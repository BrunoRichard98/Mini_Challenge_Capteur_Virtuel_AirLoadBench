{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travail developpe par le binome :\n",
    "**Bruno OLIVEIRA, Samuel GHEZI**\n",
    "\n",
    "Sur orientation de le Professeur **Martin GHIENNE**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "L’exploitation d’un avion s’accompagne de conditions de vol très variables et difficiles à prédire, ce qui rend complexe l’estimation précise des chargements structuraux rencontrés en situation réelle. Bien que des informations telles que les déformations et les contraintes soient essentielles pour optimiser la maintenance et améliorer les modèles de dimensionnement, ces grandeurs ne sont généralement pas mesurées directement sur les aéronefs commerciaux. L’installation de capteurs dédiés entraînerait en effet une augmentation significative des coûts, de la masse, de la complexité d’intégration et des exigences de certification.\n",
    "\n",
    "Le Mini-Challenge propose ainsi de développer un capteur virtuel basé sur des méthodes d’apprentissage automatique, capable d’estimer l’état de contrainte structurelle en différents points de l’avion à partir des seuls paramètres déjà enregistrés par l’instrumentation de bord. L’objectif est de prédire des grandeurs non mesurées physiquement, mais inférées à partir de variables de vol telles que l’attitude, les vitesses, les accélérations, les ordres de commande et les conditions de vent.\n",
    "\n",
    "Pour cela, un ensemble de données réelles provenant de 44 vols d’essai est mis à disposition. Ce jeu de données comprend :\n",
    "\n",
    "39 paramètres issus de l’instrumentation de bord, représentant l’état de vol, les efforts aérodynamiques et les actions de contrôle ;\n",
    "\n",
    "15 jauges d’extensométrie (en micro-déformations, με) positionnées en différents points structuraux de l’appareil, permettant de mesurer directement les contraintes locales.\n",
    "\n",
    "En résumé, ce projet vise à démontrer la capacité d’un modèle d’apprentissage supervisé à reproduire les contraintes structurelles réelles à partir de données opérationnelles courantes, ouvrant la voie à des stratégies de maintenance plus prédictives, moins coûteuses et mieux informées, dans la continuité des travaux précédents sur les capteurs virtuels pour le suivi de santé structurale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette projet, on va se baser dans la teorie de Machine Learning, en se basent dans l'image ci dessous :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Management des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le liste de variable avec les description et sont format qui existe dans les données collectées pendant les vols sont en dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Lybraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch.nn.init import kaiming_uniform_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Management des données** - Acquisition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displayng the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Management des données** - Exploration des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting grqphs for correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Management des données** - Préparation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Relative_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nz</th>\n",
       "      <th>Nx</th>\n",
       "      <th>Roll_Angle</th>\n",
       "      <th>Pitch_Angle</th>\n",
       "      <th>True_AOA</th>\n",
       "      <th>True_Sideslip</th>\n",
       "      <th>FPA</th>\n",
       "      <th>True_Heading</th>\n",
       "      <th>CAS</th>\n",
       "      <th>TAS</th>\n",
       "      <th>...</th>\n",
       "      <th>Strain7</th>\n",
       "      <th>Strain8</th>\n",
       "      <th>Strain9</th>\n",
       "      <th>Strain10</th>\n",
       "      <th>Strain11</th>\n",
       "      <th>Strain12</th>\n",
       "      <th>Strain13</th>\n",
       "      <th>Strain14</th>\n",
       "      <th>Strain15</th>\n",
       "      <th>Tol_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>-0.014912</td>\n",
       "      <td>0.147686</td>\n",
       "      <td>-0.311379</td>\n",
       "      <td>3.590025</td>\n",
       "      <td>-2.303673</td>\n",
       "      <td>146.080303</td>\n",
       "      <td>134.823861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TOL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>-0.014912</td>\n",
       "      <td>0.147686</td>\n",
       "      <td>-0.311379</td>\n",
       "      <td>3.590025</td>\n",
       "      <td>-2.303673</td>\n",
       "      <td>146.080303</td>\n",
       "      <td>134.823861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601572</td>\n",
       "      <td>-0.884219</td>\n",
       "      <td>-0.463841</td>\n",
       "      <td>0.161175</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>-0.143096</td>\n",
       "      <td>0.403351</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.175358</td>\n",
       "      <td>TOL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>-0.014912</td>\n",
       "      <td>0.147686</td>\n",
       "      <td>-0.311379</td>\n",
       "      <td>3.590025</td>\n",
       "      <td>-2.303673</td>\n",
       "      <td>146.080303</td>\n",
       "      <td>134.824664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310433</td>\n",
       "      <td>-1.410038</td>\n",
       "      <td>-1.853289</td>\n",
       "      <td>0.646155</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.571435</td>\n",
       "      <td>0.818918</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.350715</td>\n",
       "      <td>TOL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>-0.014912</td>\n",
       "      <td>0.147686</td>\n",
       "      <td>-0.311379</td>\n",
       "      <td>3.590025</td>\n",
       "      <td>-2.303673</td>\n",
       "      <td>146.080303</td>\n",
       "      <td>134.825466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424748</td>\n",
       "      <td>-1.414549</td>\n",
       "      <td>-1.854326</td>\n",
       "      <td>0.174219</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-1.013577</td>\n",
       "      <td>1.216162</td>\n",
       "      <td>-1.045466</td>\n",
       "      <td>-0.521183</td>\n",
       "      <td>TOL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>-0.014912</td>\n",
       "      <td>0.147686</td>\n",
       "      <td>-0.311379</td>\n",
       "      <td>3.590025</td>\n",
       "      <td>-2.303673</td>\n",
       "      <td>146.080303</td>\n",
       "      <td>134.825466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572497</td>\n",
       "      <td>-2.114138</td>\n",
       "      <td>2.512348</td>\n",
       "      <td>0.644700</td>\n",
       "      <td>0.579980</td>\n",
       "      <td>-0.572384</td>\n",
       "      <td>1.613406</td>\n",
       "      <td>0.691031</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>TOL_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Nz        Nx  Roll_Angle  Pitch_Angle  True_AOA  True_Sideslip  \\\n",
       "0  0.906212 -0.014912    0.147686    -0.311379  3.590025      -2.303673   \n",
       "1  0.906212 -0.014912    0.147686    -0.311379  3.590025      -2.303673   \n",
       "2  0.906212 -0.014912    0.147686    -0.311379  3.590025      -2.303673   \n",
       "3  0.906212 -0.014912    0.147686    -0.311379  3.590025      -2.303673   \n",
       "4  0.906212 -0.014912    0.147686    -0.311379  3.590025      -2.303673   \n",
       "\n",
       "          FPA  True_Heading  CAS  TAS  ...   Strain7   Strain8   Strain9  \\\n",
       "0  146.080303    134.823861  0.0  0.0  ...  0.000000  0.000000  0.000000   \n",
       "1  146.080303    134.823861  0.0  0.0  ... -0.601572 -0.884219 -0.463841   \n",
       "2  146.080303    134.824664  0.0  0.0  ... -0.310433 -1.410038 -1.853289   \n",
       "3  146.080303    134.825466  0.0  0.0  ...  0.424748 -1.414549 -1.854326   \n",
       "4  146.080303    134.825466  0.0  0.0  ...  0.572497 -2.114138  2.512348   \n",
       "\n",
       "   Strain10  Strain11  Strain12  Strain13  Strain14  Strain15  Tol_ID  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   TOL_1  \n",
       "1  0.161175 -0.000325 -0.143096  0.403351  0.006286  0.175358   TOL_1  \n",
       "2  0.646155 -0.000651 -0.571435  0.818918  0.012573  0.350715   TOL_1  \n",
       "3  0.174219 -0.000976 -1.013577  1.216162 -1.045466 -0.521183   TOL_1  \n",
       "4  0.644700  0.579980 -0.572384  1.613406  0.691031  0.003260   TOL_1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Nz', 'Nx', 'Roll_Angle', 'Pitch_Angle', 'True_AOA', 'True_Sideslip', 'FPA', 'True_Heading', 'CAS', 'TAS', 'Mach', 'SAT', 'Baro_Alt', 'Roll_Rate', 'Pitch_Rate', 'Heading_Rate', 'Fuel_Qty1', 'Fuel_Qty2', 'L_Eng_Start', 'R_Eng_Start', 'L_Throttle_Pos', 'R_Throttle_Pos', 'L_Eng_N1', 'R_Eng_N1', 'L_Eng_N2', 'R_Eng_N2', 'L_Gear_Down', 'R_Gear_Down', 'N_Gear_Down', 'L_Flaperon_Pos', 'R_Flaperon_Pos', 'L_LEF_Pos', 'R_LEF_Pos', 'L_Rudder_Pos', 'L_Stab_Pos', 'R_Stab_Pos', 'Stick_Pitch', 'Stick_Roll', 'Pedal_Pos']\n",
      "Targets : ['Strain1', 'Strain2', 'Strain3', 'Strain4', 'Strain5', 'Strain6', 'Strain7', 'Strain8', 'Strain9', 'Strain10', 'Strain11', 'Strain12', 'Strain13', 'Strain14', 'Strain15']\n"
     ]
    }
   ],
   "source": [
    "# Targets = deformações (saídas do modelo)\n",
    "target_cols = [f\"Strain{i}\" for i in range(1, 16)]\n",
    "\n",
    "# Features = todas as colunas menos Strains e Flight_ID\n",
    "feature_cols = [c for c in df.columns if c not in target_cols + [\"Tol_ID\"]]\n",
    "\n",
    "print(\"Features:\", feature_cols)\n",
    "print(\"Targets :\", target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas com NaN nas colunas importantes\n",
    "df_clean = df.dropna(subset=feature_cols + target_cols)\n",
    "\n",
    "X = df_clean[feature_cols].values      # entradas\n",
    "y = df_clean[target_cols].values      # saídas (strains)\n",
    "Tol_ids = df_clean[\"Tol_ID\"].values  # de qual TOL é cada linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp, ids_train, ids_temp = train_test_split(\n",
    "    X, y, Tol_ids,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=Tol_ids\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test, ids_val, ids_test = train_test_split(\n",
    "    X_temp, y_temp, ids_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=ids_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled   = scaler_X.transform(X_val)\n",
    "X_test_scaled  = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled   = scaler_y.transform(y_val)\n",
    "y_test_scaled  = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrainDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq = self.X[idx : idx + self.seq_len]\n",
    "        y_seq = self.y[idx : idx + self.seq_len]\n",
    "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_seq, dtype=torch.float32)\n",
    "sequence_len1 = 20\n",
    "sequence_len2 = 100\n",
    "train_ds = StrainDataset(X_train_scaled, y_train_scaled, sequence_len2)\n",
    "val_ds   = StrainDataset(X_val_scaled,   y_val_scaled, sequence_len2)\n",
    "test_ds  = StrainDataset(X_test_scaled,  y_test_scaled, sequence_len2)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre problème est dynamique car différentes variables dépendent du temps. Comme les variables sont nombreuses il serait aussi intéressant de réduire nos nombres de variables pour caractériser au mieux dans un minimum de variable notre problème. Ainsi, la solution choisit serait un `Multi-modèle` :\n",
    "- En premier lieu, nous allons réduire nos variables en un espace latent z avec un `Encodeur` qui caractérise au mieux \"spatialement\" notre problème.\n",
    "- Nous souhaitons aussi avoir des \"fenêtres temporelles d'informations\" afin de relier certaine grandeur physiques au temps. Ainsi, la seconde \"couche\" de notre modèle seront des couches `LSTM` qui relie nos informations au temps, et qui rend un tenseur avec les derniers état caché de chaque cellule.\n",
    "- Finalement, nos informations passe par des dernières couches d'un `MLP` linéaire standard qui permettent la prédiction des contraintes appliquée à notre avion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Encoder layers***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "à l'inverse du premier modèle instancié au hasard, on propose ici un mlti modèle \"variable\"(avec des valeurs par défaut si non précisées). on pourra part la suite choisir des intervalles de recherches pour nos hyper paramètre avec un optimiseur d'hyperparamètre. Celui choisit pour l'étude sera `Optuna`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):#réduction de nos variable en un espace latent z qui caractérise au mieux nos données.\n",
    "    def __init__(self, input_size, nb_percp=64, nb_layers=3, z_dim = 16):\n",
    "        super().__init__() #on appelle la classe parent Module\n",
    "        layers = []\n",
    "        in_dim = input_size\n",
    "        for _ in range(nb_layers): #comme le nombre de couches est inconnu, il est donc nécessaire d'utiliser une boucle for pour créer notre classe\n",
    "            linear = nn.Linear(in_dim, nb_percp)\n",
    "            kaiming_uniform_(linear.weight, nonlinearity='relu')\n",
    "            layers.append(linear)#on ajoute la couche linéaire à une liste qui correspond à notre réseau caché - la dernière couche\n",
    "            layers.append(nn.ReLU()) #sans oublier les fonction d'activation\n",
    "            in_dim = nb_percp # après être passé une première fois dans la boucle, nos couches auront le même nombres de neuronnes\n",
    "        output = nn.Linear(in_dim, z_dim) \n",
    "        kaiming_uniform_(output.weight, nonlinearity='relu')\n",
    "        layers.append(output) #on ajoute la dernière couche de notre encoder\n",
    "        self.net = nn.Sequential(*layers) #on appelle le pointeur de la liste pour récupérer les différentes couches et créer le \"net\" total.\n",
    "         #la fonction reLU a le gradiant le plus stable, elle semble donc être un bon choix pour notre projet.\n",
    "    def forward (self, x): #passage du tenseur dans les différentes couches de notre Encoder\n",
    "        return self.net(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LSTM Layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstm(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, nb_layers: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "            on initialise notre système avec un dropout faible\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size # récupère la taille des vecteurs des valeurs d'entrées\n",
    "        self.hidden_size = hidden_size  # récupère le nombre de cellules par couche de lstm\n",
    "        self.nb_layers = nb_layers  # récupère le nombre de couche dans le LSTM\n",
    "        # Défini les couches LSTM\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=nb_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # on fait passer l'entrée par les différente cellules du lstm\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MLP predictive layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_v2(nn.Module):\n",
    "    def __init__(self, input_size, nb_percp = 128, nb_layers = 3, n_contraintes = 15):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = input_size\n",
    "        for _ in range(nb_layers):#on applique la même réflexion que l'encoder au mlp qui donne les différentes contraintes en sortie.\n",
    "            linear = nn.Linear(in_dim, nb_percp)\n",
    "            kaiming_uniform_(linear.weight, nonlinearity='relu')\n",
    "            layers.append(linear)\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = nb_percp\n",
    "        output = nn.Linear(in_dim, n_contraintes)\n",
    "        kaiming_uniform_(output.weight, nonlinearity='linear')\n",
    "        layers.append(output)\n",
    "        self.net = nn.Sequential(*layers)\n",
    "         #la fonction reLU a le gradiant le plus stable, elle semble donc être un bon choix pour notre projet.\n",
    "    def forward (self, x): #passage du tenseur dans les différentes couches de notre Encoder.\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mercosur(nn.Module):\n",
    "    def __init__(self, input_size, nb_percp_enc, nb_layers_enc, z_dim, hidden_size_lstm, nb_layers_lstm, nb_percp_mlp, nb_layers_mlp, n_contraintes):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = Encoder(input_size, nb_percp_enc, nb_layers_enc, z_dim)\n",
    "        self.lstm_layers = Lstm(z_dim, hidden_size_lstm, nb_layers_lstm)\n",
    "        # self.mlp_layers = MLP(hidden_size, n_contraintes).\n",
    "        self.mlp_layers = MLP_v2(hidden_size_lstm, nb_percp_mlp, nb_layers_mlp, n_contraintes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, n_features)\n",
    "        z_seq = self.encoder_layers(x)      # (batch, seq_len, z_dim)\n",
    "        h_seq = self.lstm_layers(z_seq)     # (batch, seq_len, hidden_size)\n",
    "        y_pred = self.mlp_layers(h_seq)     # (batch, seq_len, n_contraintes)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (X_batch, y_batch) in enumerate(tqdm(loader)):\n",
    "        # ver o shape só no primeiro batch\n",
    "        if i == 0:\n",
    "            print(\"X_batch shape:\", X_batch.shape)\n",
    "            print(\"y_batch shape:\", y_batch.shape)\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (X_batch, y_batch) in enumerate(loader):\n",
    "\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    return running_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{torch.Size([256, 100, 39])}\n"
     ]
    }
   ],
   "source": [
    "print({next(iter(train_loader))[0].shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def train(capteur_model, train_loader, val_loader, optimizer, criterion, epochs = 30):\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(capteur_model, train_loader, optimizer, criterion)\n",
    "        val_loss   = eval_epoch(capteur_model, val_loader, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1:03d} | Train: {train_loss:.6f} | Val: {val_loss:.6f}\")\n",
    "    return capteur_model, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le multi modèle devrai avoir une représentation spatiale et temporelle \"juste\" du problème. par rapport au modèle précédent, la séquence d'étude du LSTM a augmentée. Nous sommes passé de 20 pas de temps à 100. Certain phénomène physique récupérés par les différents capteurs sont reliée au temps mais si l'intervalle étudiée est trop petite, il se pourrait que seulement un régime transitoire soit étudié (pas de temps de 0.032s). il reste à déterminer à quel point nos hyperparamètres sont fiable. Afin de s'en assurer, on utilise la librairie optuna, un optimiseur d'hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pour l'instant, l'optimisation se fera sur plusieurs faibles couples d'hyperparamètres afin de ne pas trop surcharger le gpu et diminuer le temps de réponse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#on récupère la taille du vecteur d'entrée et de sortie voulu pour notre multi-modèle\n",
    "n_features = X_train_scaled.shape[-1]\n",
    "n_outputs  = y_train_scaled.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On instancie une fonction objective1 qui donne en sortie la métrique que l'on souhaite minimiser avec l'optimiseur d'hyper paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective1(trial):\n",
    "    # nb_percps_enc = trial.suggest_int(\"nb_percps_enc\",30, 60)\n",
    "    # nb_percps_mlp = trial.suggest_int(\"nb_percps_mlp\",128, 256)\n",
    "    # num_layersenc = trial.suggest_int(\"num_layers_enc\", 1, 5)\n",
    "    # num_layerslstm = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "    # num_layersmlp = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "    n_features = X_train_scaled.shape[-1]\n",
    "    n_outputs  = y_train_scaled.shape[-1]\n",
    "    #ici on fixe des valeurs afin d'assurer un temps de réponse \"plutot\" faible. Cela serait trop couteûx de minimiser la rmse avec 8variables à déterminer\n",
    "    nb_percps_enc = 32 \n",
    "    nb_percps_mlp = 128\n",
    "    num_layersenc = 3\n",
    "    num_layerslstm = 3\n",
    "    num_layersmlp = 3\n",
    "    #nous porterons notre attention dans un premier temps sur z_dim et le nombre de cellules du lstm\n",
    "    #afin de savoir quelle sont les meilleure valeurs pour caractériser spatialement et temporellement notre problème\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 10, 20)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    hidden_size_lstm = trial.suggest_int(\"hidden_size\", 30, 70)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    opti_mercosur = Mercosur(n_features, nb_percps_enc, num_layersenc, z_dim, hidden_size_lstm, num_layerslstm, nb_percps_mlp, num_layersmlp, n_outputs).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    opti_optimizer = optim.Adam(opti_mercosur.parameters(), lr= lr)\n",
    "    train(opti_mercosur, train_loader, val_loader, opti_optimizer, loss_fn)\n",
    "\n",
    "    opti_mercosur.eval()\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred = opti_mercosur(X_batch)\n",
    "            y_pred_list.append(y_pred.cpu().numpy())\n",
    "    y_pred_scaled = np.concatenate(y_pred_list, axis=0)\n",
    "    y_pred_scaled_2d = y_pred_scaled.reshape(-1, D)  # (N*T, D)\n",
    "    y_pred_real = scaler_y.inverse_transform(y_pred_scaled_2d)\n",
    "    rmse_global = mean_squared_error(y_test, y_pred_real, squared=False)\n",
    "    return rmse_global #on choisira la rmse à minimiser car c'est celle demandée par le projet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on créer une étude Optuna qui récupère la fonction objective1 et qui avec n_trials essai, essaie de minimiser la rmse( et plus généralement la sortie de notre fonction prit en argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective1, n_trials = 30) #ili y aura 30 essai pour minimiser la rmse\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best MSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on récupère le modèle avec la meilleure rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (597658585.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[50], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    num_layersenc = 3\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "nb_percps_enc = 32 \n",
    "nb_percps_mlp = 128\n",
    "num_layersenc = 3\n",
    "num_layerslstm = 3\n",
    "num_layersmlp = 3\n",
    "n_features = X_train_scaled.shape[-1]\n",
    "n_outputs  = y_train_scaled.shape[-1]\n",
    "best_model = study.best_trial\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_mercosur = Mercosur(n_features, nb_percps_enc, num_layersenc, best_model[\"z_dim\"], best_model[\"hidden_size_lstm\"], num_layerslstm, nb_percps_mlp, num_layersmlp, n_outputs).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "best_optimizer = optim.Adam(best_mercosur.parameters(), lr= best_model[\"lr\"])\n",
    "train_losses, test_losses, final_mercosur = train(best_mercosur, train_loader, val_loader, best_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_mercosur.state_dict(), \"best_mercosur.pth\")\n",
    "print(\"model saved in 'best_mercosur.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(epochs, val_losses,   label=\"Validation Loss\", marker='s')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('Train_vs_Validation_Loss_Mercosur.png', dpi=300)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"Train_vs_Validation_Loss_Mercosur.png\")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall metrics in the test set:\n",
      "MAE  : 20.5281\n",
      "RMSE : 34.9109\n",
      "R²   : 0.9500\n"
     ]
    }
   ],
   "source": [
    "final_mercosur.eval()\n",
    "\n",
    "\n",
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "\n",
    "        # forward no modelo\n",
    "        y_pred = final_mercosur(X_batch)  # (batch, seq_len, n_outputs)\n",
    "\n",
    "        # manda tudo pra CPU e acumula\n",
    "        \n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "\n",
    "y_pred_scaled = np.concatenate(y_pred_list, axis=0)  # (N, T, D)\n",
    "\n",
    "# achata a dimensão temporal pra usar no scaler (espera 2D)\n",
    "N, T, D = y_pred_scaled.shape\n",
    "\n",
    "y_pred_scaled_2d = y_pred_scaled.reshape(-1, D)  # (N*T, D)\n",
    "\n",
    "# volta pro espaço real\n",
    "\n",
    "y_pred_real = scaler_y.inverse_transform(y_pred_scaled_2d)\n",
    "\n",
    "# métricas globais\n",
    "mae_global  = mean_absolute_error(y_test, y_pred_real)\n",
    "rmse_global = mean_squared_error(y_test, y_pred_real, squared=False)\n",
    "r2_global   = r2_score(y_test, y_pred_real)\n",
    "\n",
    "print(\"Overall metrics in the test set:\")\n",
    "print(f\"MAE  : {mae_global:.4f}\")\n",
    "print(f\"RMSE : {rmse_global:.4f}\")\n",
    "print(f\"R²   : {r2_global:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lire les images de le training up side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = y_pred_scaled.shape[1]\n",
    "N_seq_pred = y_pred_scaled.shape[0]\n",
    "\n",
    "ids_test_eff = ids_test[:N_seq_pred]\n",
    "ids_test_step = np.repeat(ids_test_eff, T)\n",
    "\n",
    "metrics_per_flight = {}\n",
    "unique_flights = np.unique(ids_test_eff)\n",
    "\n",
    "for flight in unique_flights:\n",
    "    mask = (ids_test_step == flight)\n",
    "\n",
    "    y_true_f = y_test[mask]\n",
    "    y_pred_f = y_pred_real[mask]\n",
    "\n",
    "    mae  = mean_absolute_error(y_true_f, y_pred_f)\n",
    "    rmse = mean_squared_error(y_true_f, y_pred_f, squared=False)\n",
    "    r2   = r2_score(y_true_f, y_pred_f)\n",
    "\n",
    "    metrics_per_flight[flight] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = pd.DataFrame.from_dict(metrics_per_flight, orient='index')\n",
    "\n",
    "# adicionar as métricas globais\n",
    "df_global = pd.DataFrame({\n",
    "    \"MAE\":  [mae_global],\n",
    "    \"RMSE\": [rmse_global],\n",
    "    \"R2\":   [r2_global]\n",
    "}, index=[\"GLOBAL\"])\n",
    "\n",
    "# concatenar tudo\n",
    "df_results = pd.concat([df_flights, df_global])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('df_results_multi_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOL_1</th>\n",
       "      <td>21.411116</td>\n",
       "      <td>35.396049</td>\n",
       "      <td>0.950829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_10</th>\n",
       "      <td>21.469473</td>\n",
       "      <td>35.473278</td>\n",
       "      <td>0.949585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_11</th>\n",
       "      <td>21.668261</td>\n",
       "      <td>35.956020</td>\n",
       "      <td>0.948748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_12</th>\n",
       "      <td>21.871603</td>\n",
       "      <td>36.244915</td>\n",
       "      <td>0.948428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_13</th>\n",
       "      <td>21.405066</td>\n",
       "      <td>35.142048</td>\n",
       "      <td>0.950851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_14</th>\n",
       "      <td>21.944002</td>\n",
       "      <td>36.332851</td>\n",
       "      <td>0.948736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_15</th>\n",
       "      <td>21.899666</td>\n",
       "      <td>36.122211</td>\n",
       "      <td>0.949418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_17</th>\n",
       "      <td>21.490608</td>\n",
       "      <td>35.413269</td>\n",
       "      <td>0.950260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_18</th>\n",
       "      <td>21.938776</td>\n",
       "      <td>36.316383</td>\n",
       "      <td>0.948756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_19</th>\n",
       "      <td>21.660200</td>\n",
       "      <td>36.023014</td>\n",
       "      <td>0.948947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_2</th>\n",
       "      <td>21.414541</td>\n",
       "      <td>35.397785</td>\n",
       "      <td>0.950015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_20</th>\n",
       "      <td>21.815008</td>\n",
       "      <td>35.961296</td>\n",
       "      <td>0.948540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_21</th>\n",
       "      <td>21.432972</td>\n",
       "      <td>35.630138</td>\n",
       "      <td>0.950562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_22</th>\n",
       "      <td>21.289389</td>\n",
       "      <td>35.317715</td>\n",
       "      <td>0.949439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_23</th>\n",
       "      <td>21.440657</td>\n",
       "      <td>35.618309</td>\n",
       "      <td>0.949125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_24</th>\n",
       "      <td>21.344246</td>\n",
       "      <td>35.257652</td>\n",
       "      <td>0.950118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_25</th>\n",
       "      <td>21.521358</td>\n",
       "      <td>35.470242</td>\n",
       "      <td>0.950835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_26</th>\n",
       "      <td>21.781605</td>\n",
       "      <td>36.171371</td>\n",
       "      <td>0.950266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_27</th>\n",
       "      <td>21.654949</td>\n",
       "      <td>35.665577</td>\n",
       "      <td>0.949032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_28</th>\n",
       "      <td>21.801271</td>\n",
       "      <td>36.081509</td>\n",
       "      <td>0.948449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_29</th>\n",
       "      <td>21.522869</td>\n",
       "      <td>35.524986</td>\n",
       "      <td>0.950558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_3</th>\n",
       "      <td>21.393728</td>\n",
       "      <td>35.486313</td>\n",
       "      <td>0.950744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_30</th>\n",
       "      <td>21.477079</td>\n",
       "      <td>35.682919</td>\n",
       "      <td>0.948847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_31</th>\n",
       "      <td>21.628981</td>\n",
       "      <td>35.949284</td>\n",
       "      <td>0.949606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_33</th>\n",
       "      <td>21.365887</td>\n",
       "      <td>35.278015</td>\n",
       "      <td>0.950579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_34</th>\n",
       "      <td>21.343571</td>\n",
       "      <td>35.210281</td>\n",
       "      <td>0.952845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_35</th>\n",
       "      <td>22.127098</td>\n",
       "      <td>36.802723</td>\n",
       "      <td>0.947293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_36</th>\n",
       "      <td>21.700615</td>\n",
       "      <td>35.913834</td>\n",
       "      <td>0.949798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_37</th>\n",
       "      <td>21.483227</td>\n",
       "      <td>35.533932</td>\n",
       "      <td>0.950894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_38</th>\n",
       "      <td>21.603588</td>\n",
       "      <td>35.718193</td>\n",
       "      <td>0.950396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_39</th>\n",
       "      <td>21.518625</td>\n",
       "      <td>35.580921</td>\n",
       "      <td>0.951295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_4</th>\n",
       "      <td>21.967323</td>\n",
       "      <td>36.647144</td>\n",
       "      <td>0.947827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_40</th>\n",
       "      <td>21.702488</td>\n",
       "      <td>36.137161</td>\n",
       "      <td>0.950845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_41</th>\n",
       "      <td>21.273962</td>\n",
       "      <td>35.204613</td>\n",
       "      <td>0.953076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_42</th>\n",
       "      <td>21.374058</td>\n",
       "      <td>35.322521</td>\n",
       "      <td>0.950951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_43</th>\n",
       "      <td>21.517933</td>\n",
       "      <td>35.572582</td>\n",
       "      <td>0.950761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_44</th>\n",
       "      <td>21.596159</td>\n",
       "      <td>35.754696</td>\n",
       "      <td>0.949736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_46</th>\n",
       "      <td>21.791815</td>\n",
       "      <td>36.169296</td>\n",
       "      <td>0.948659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_48</th>\n",
       "      <td>21.465504</td>\n",
       "      <td>35.424213</td>\n",
       "      <td>0.951548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_5</th>\n",
       "      <td>21.903414</td>\n",
       "      <td>36.419926</td>\n",
       "      <td>0.947556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_6</th>\n",
       "      <td>21.254772</td>\n",
       "      <td>35.193272</td>\n",
       "      <td>0.950024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_7</th>\n",
       "      <td>21.938131</td>\n",
       "      <td>36.122883</td>\n",
       "      <td>0.949584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_8</th>\n",
       "      <td>21.816338</td>\n",
       "      <td>35.961205</td>\n",
       "      <td>0.949991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL_9</th>\n",
       "      <td>21.620155</td>\n",
       "      <td>35.823257</td>\n",
       "      <td>0.950874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOBAL</th>\n",
       "      <td>20.528065</td>\n",
       "      <td>34.910885</td>\n",
       "      <td>0.949995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MAE       RMSE        R2\n",
       "TOL_1   21.411116  35.396049  0.950829\n",
       "TOL_10  21.469473  35.473278  0.949585\n",
       "TOL_11  21.668261  35.956020  0.948748\n",
       "TOL_12  21.871603  36.244915  0.948428\n",
       "TOL_13  21.405066  35.142048  0.950851\n",
       "TOL_14  21.944002  36.332851  0.948736\n",
       "TOL_15  21.899666  36.122211  0.949418\n",
       "TOL_17  21.490608  35.413269  0.950260\n",
       "TOL_18  21.938776  36.316383  0.948756\n",
       "TOL_19  21.660200  36.023014  0.948947\n",
       "TOL_2   21.414541  35.397785  0.950015\n",
       "TOL_20  21.815008  35.961296  0.948540\n",
       "TOL_21  21.432972  35.630138  0.950562\n",
       "TOL_22  21.289389  35.317715  0.949439\n",
       "TOL_23  21.440657  35.618309  0.949125\n",
       "TOL_24  21.344246  35.257652  0.950118\n",
       "TOL_25  21.521358  35.470242  0.950835\n",
       "TOL_26  21.781605  36.171371  0.950266\n",
       "TOL_27  21.654949  35.665577  0.949032\n",
       "TOL_28  21.801271  36.081509  0.948449\n",
       "TOL_29  21.522869  35.524986  0.950558\n",
       "TOL_3   21.393728  35.486313  0.950744\n",
       "TOL_30  21.477079  35.682919  0.948847\n",
       "TOL_31  21.628981  35.949284  0.949606\n",
       "TOL_33  21.365887  35.278015  0.950579\n",
       "TOL_34  21.343571  35.210281  0.952845\n",
       "TOL_35  22.127098  36.802723  0.947293\n",
       "TOL_36  21.700615  35.913834  0.949798\n",
       "TOL_37  21.483227  35.533932  0.950894\n",
       "TOL_38  21.603588  35.718193  0.950396\n",
       "TOL_39  21.518625  35.580921  0.951295\n",
       "TOL_4   21.967323  36.647144  0.947827\n",
       "TOL_40  21.702488  36.137161  0.950845\n",
       "TOL_41  21.273962  35.204613  0.953076\n",
       "TOL_42  21.374058  35.322521  0.950951\n",
       "TOL_43  21.517933  35.572582  0.950761\n",
       "TOL_44  21.596159  35.754696  0.949736\n",
       "TOL_46  21.791815  36.169296  0.948659\n",
       "TOL_48  21.465504  35.424213  0.951548\n",
       "TOL_5   21.903414  36.419926  0.947556\n",
       "TOL_6   21.254772  35.193272  0.950024\n",
       "TOL_7   21.938131  36.122883  0.949584\n",
       "TOL_8   21.816338  35.961205  0.949991\n",
       "TOL_9   21.620155  35.823257  0.950874\n",
       "GLOBAL  20.528065  34.910885  0.949995"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results = pd.read_csv('df_results_all.csv')\n",
    "df_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Data (hugo jtm)",
   "language": "python",
   "name": "deep_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
